{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IZiqEvXM-xKi"},"source":["# Anonymous Ratings from the Jester Online Joke Recommender System"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V5KvcHWD-xKk"},"source":["# Abstract:\n","\n","Ratings are real values ranging from -10.00 to +10.00 (the value \"99\" corresponds to \"null\" = \"not rated\").\n","\n","One row per user\n","\n","The first column gives the number of jokes rated by that user. The next 100 columns give the ratings for jokes 01 - 100."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bZxbkWW6-xKl"},"source":["# Dataset:\n","    \n","http://eigentaste.berkeley.edu/dataset/\n","\n","The text of the jokes can be downloaded here: jester_dataset_1_joke_texts.zip (92KB)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x2uWajXL-xKm"},"source":["Read the dataset(jokes.csv)\n","\n","Take care about the header in read_csv() as there are no column names given in the dataset."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"YENBwOew-xKo"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","id":"ykl5yguG-xKu"},"outputs":[],"source":["data = pd.read_csv('./dataset/jokes.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","id":"3AvCeFDt-xKz","outputId":"8d0663e2-e8b8-4988-ff47-1f9ff43ec864"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>74</th>\n","      <th>-7.82</th>\n","      <th>8.79</th>\n","      <th>-9.66</th>\n","      <th>-8.16</th>\n","      <th>-7.52</th>\n","      <th>-8.5</th>\n","      <th>-9.85</th>\n","      <th>4.17</th>\n","      <th>-8.98</th>\n","      <th>...</th>\n","      <th>2.82.2</th>\n","      <th>99.18</th>\n","      <th>99.19</th>\n","      <th>99.20</th>\n","      <th>99.21</th>\n","      <th>99.22</th>\n","      <th>-5.63</th>\n","      <th>99.23</th>\n","      <th>99.24</th>\n","      <th>99.25</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100</td>\n","      <td>4.08</td>\n","      <td>-0.29</td>\n","      <td>6.36</td>\n","      <td>4.37</td>\n","      <td>-2.38</td>\n","      <td>-9.66</td>\n","      <td>-0.73</td>\n","      <td>-5.34</td>\n","      <td>8.88</td>\n","      <td>...</td>\n","      <td>2.82</td>\n","      <td>-4.95</td>\n","      <td>-0.29</td>\n","      <td>7.86</td>\n","      <td>-0.19</td>\n","      <td>-2.14</td>\n","      <td>3.06</td>\n","      <td>0.34</td>\n","      <td>-4.32</td>\n","      <td>1.07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>49</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>9.03</td>\n","      <td>9.27</td>\n","      <td>9.03</td>\n","      <td>9.27</td>\n","      <td>99.00</td>\n","      <td>...</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>9.08</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>48</td>\n","      <td>99.00</td>\n","      <td>8.35</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>1.80</td>\n","      <td>8.16</td>\n","      <td>-2.82</td>\n","      <td>6.21</td>\n","      <td>99.00</td>\n","      <td>...</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>0.53</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","      <td>99.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>91</td>\n","      <td>8.50</td>\n","      <td>4.61</td>\n","      <td>-4.17</td>\n","      <td>-5.39</td>\n","      <td>1.36</td>\n","      <td>1.60</td>\n","      <td>7.04</td>\n","      <td>4.61</td>\n","      <td>-0.44</td>\n","      <td>...</td>\n","      <td>5.19</td>\n","      <td>5.58</td>\n","      <td>4.27</td>\n","      <td>5.19</td>\n","      <td>5.73</td>\n","      <td>1.55</td>\n","      <td>3.11</td>\n","      <td>6.55</td>\n","      <td>1.80</td>\n","      <td>1.60</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>100</td>\n","      <td>-6.17</td>\n","      <td>-3.54</td>\n","      <td>0.44</td>\n","      <td>-8.50</td>\n","      <td>-7.09</td>\n","      <td>-4.32</td>\n","      <td>-8.69</td>\n","      <td>-0.87</td>\n","      <td>-6.65</td>\n","      <td>...</td>\n","      <td>-3.54</td>\n","      <td>-6.89</td>\n","      <td>-0.68</td>\n","      <td>-2.96</td>\n","      <td>-2.18</td>\n","      <td>-3.35</td>\n","      <td>0.05</td>\n","      <td>-9.08</td>\n","      <td>-5.05</td>\n","      <td>-3.45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 101 columns</p>\n","</div>"],"text/plain":["    74  -7.82   8.79  -9.66  -8.16  -7.52  -8.5  -9.85  4.17  -8.98  ...  \\\n","0  100   4.08  -0.29   6.36   4.37  -2.38 -9.66  -0.73 -5.34   8.88  ...   \n","1   49  99.00  99.00  99.00  99.00   9.03  9.27   9.03  9.27  99.00  ...   \n","2   48  99.00   8.35  99.00  99.00   1.80  8.16  -2.82  6.21  99.00  ...   \n","3   91   8.50   4.61  -4.17  -5.39   1.36  1.60   7.04  4.61  -0.44  ...   \n","4  100  -6.17  -3.54   0.44  -8.50  -7.09 -4.32  -8.69 -0.87  -6.65  ...   \n","\n","   2.82.2  99.18  99.19  99.20  99.21  99.22  -5.63  99.23  99.24  99.25  \n","0    2.82  -4.95  -0.29   7.86  -0.19  -2.14   3.06   0.34  -4.32   1.07  \n","1   99.00  99.00  99.00   9.08  99.00  99.00  99.00  99.00  99.00  99.00  \n","2   99.00  99.00  99.00   0.53  99.00  99.00  99.00  99.00  99.00  99.00  \n","3    5.19   5.58   4.27   5.19   5.73   1.55   3.11   6.55   1.80   1.60  \n","4   -3.54  -6.89  -0.68  -2.96  -2.18  -3.35   0.05  -9.08  -5.05  -3.45  \n","\n","[5 rows x 101 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aGt98hXQ-xK5"},"source":["Consider ratings named dataframe with only first 200 rows and all columns from 1(first column is 0) of dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","id":"vjStM8Iz-xK6"},"outputs":[],"source":["ratings = data.iloc[:200,1:]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iegd-hf8-xLD"},"source":["Change the column indices from 0 to 99"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","id":"gE3hf2OC-xLE"},"outputs":[],"source":["ratings.columns = range(ratings.shape[1])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qCshyupJ-xLK"},"source":["In the dataset, the null ratings are given as 99.00, so replace all 99.00s with 0\n","\n","Hint: You can use ratings.replace(<the given value>, <new value you wanted to change with>)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","id":"UCGWvrsk-xLL"},"outputs":[],"source":["ratings = ratings.replace(99.0, 0)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{},"colab_type":"code","id":"pzDIt950-xLR","outputId":"e8006e1c-e402-4184-a2b8-e25e35701bec"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.08</td>\n","      <td>-0.29</td>\n","      <td>6.36</td>\n","      <td>4.37</td>\n","      <td>-2.38</td>\n","      <td>-9.66</td>\n","      <td>-0.73</td>\n","      <td>-5.34</td>\n","      <td>8.88</td>\n","      <td>9.22</td>\n","      <td>...</td>\n","      <td>2.82</td>\n","      <td>-4.95</td>\n","      <td>-0.29</td>\n","      <td>7.86</td>\n","      <td>-0.19</td>\n","      <td>-2.14</td>\n","      <td>3.06</td>\n","      <td>0.34</td>\n","      <td>-4.32</td>\n","      <td>1.07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>9.03</td>\n","      <td>9.27</td>\n","      <td>9.03</td>\n","      <td>9.27</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>9.08</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>8.35</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.80</td>\n","      <td>8.16</td>\n","      <td>-2.82</td>\n","      <td>6.21</td>\n","      <td>0.00</td>\n","      <td>1.84</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.53</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8.50</td>\n","      <td>4.61</td>\n","      <td>-4.17</td>\n","      <td>-5.39</td>\n","      <td>1.36</td>\n","      <td>1.60</td>\n","      <td>7.04</td>\n","      <td>4.61</td>\n","      <td>-0.44</td>\n","      <td>5.73</td>\n","      <td>...</td>\n","      <td>5.19</td>\n","      <td>5.58</td>\n","      <td>4.27</td>\n","      <td>5.19</td>\n","      <td>5.73</td>\n","      <td>1.55</td>\n","      <td>3.11</td>\n","      <td>6.55</td>\n","      <td>1.80</td>\n","      <td>1.60</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-6.17</td>\n","      <td>-3.54</td>\n","      <td>0.44</td>\n","      <td>-8.50</td>\n","      <td>-7.09</td>\n","      <td>-4.32</td>\n","      <td>-8.69</td>\n","      <td>-0.87</td>\n","      <td>-6.65</td>\n","      <td>-1.80</td>\n","      <td>...</td>\n","      <td>-3.54</td>\n","      <td>-6.89</td>\n","      <td>-0.68</td>\n","      <td>-2.96</td>\n","      <td>-2.18</td>\n","      <td>-3.35</td>\n","      <td>0.05</td>\n","      <td>-9.08</td>\n","      <td>-5.05</td>\n","      <td>-3.45</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>1.80</td>\n","      <td>5.39</td>\n","      <td>8.06</td>\n","      <td>-0.10</td>\n","      <td>4.81</td>\n","      <td>4.66</td>\n","      <td>-7.09</td>\n","      <td>-7.72</td>\n","      <td>3.69</td>\n","      <td>4.47</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>2.62</td>\n","      <td>-3.79</td>\n","      <td>-1.17</td>\n","      <td>-0.44</td>\n","      <td>-1.02</td>\n","      <td>5.05</td>\n","      <td>-3.69</td>\n","      <td>2.18</td>\n","      <td>3.30</td>\n","      <td>-0.73</td>\n","      <td>...</td>\n","      <td>1.41</td>\n","      <td>-2.52</td>\n","      <td>-0.53</td>\n","      <td>-1.89</td>\n","      <td>1.17</td>\n","      <td>-2.04</td>\n","      <td>-1.17</td>\n","      <td>-0.73</td>\n","      <td>0.73</td>\n","      <td>0.44</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>7.91</td>\n","      <td>0.00</td>\n","      <td>3.64</td>\n","      <td>-1.89</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>...</td>\n","      <td>2.96</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>5.58</td>\n","      <td>-7.28</td>\n","      <td>-4.56</td>\n","      <td>2.67</td>\n","      <td>7.38</td>\n","      <td>2.18</td>\n","      <td>2.14</td>\n","      <td>2.23</td>\n","      <td>5.58</td>\n","      <td>-4.51</td>\n","      <td>...</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>5.83</td>\n","      <td>7.09</td>\n","      <td>1.26</td>\n","      <td>7.86</td>\n","      <td>8.88</td>\n","      <td>3.93</td>\n","      <td>2.96</td>\n","      <td>...</td>\n","      <td>8.25</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 100 columns</p>\n","</div>"],"text/plain":["       0     1     2     3     4     5     6     7     8     9   ...    90  \\\n","0    4.08 -0.29  6.36  4.37 -2.38 -9.66 -0.73 -5.34  8.88  9.22  ...  2.82   \n","1    0.00  0.00  0.00  0.00  9.03  9.27  9.03  9.27  0.00  0.00  ...  0.00   \n","2    0.00  8.35  0.00  0.00  1.80  8.16 -2.82  6.21  0.00  1.84  ...  0.00   \n","3    8.50  4.61 -4.17 -5.39  1.36  1.60  7.04  4.61 -0.44  5.73  ...  5.19   \n","4   -6.17 -3.54  0.44 -8.50 -7.09 -4.32 -8.69 -0.87 -6.65 -1.80  ... -3.54   \n","..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n","195  1.80  5.39  8.06 -0.10  4.81  4.66 -7.09 -7.72  3.69  4.47  ...  0.00   \n","196  2.62 -3.79 -1.17 -0.44 -1.02  5.05 -3.69  2.18  3.30 -0.73  ...  1.41   \n","197  0.00  0.00  0.00  0.00  7.91  0.00  3.64 -1.89  0.00  0.00  ...  2.96   \n","198  5.58 -7.28 -4.56  2.67  7.38  2.18  2.14  2.23  5.58 -4.51  ...  0.00   \n","199  0.00  0.00  0.00  5.83  7.09  1.26  7.86  8.88  3.93  2.96  ...  8.25   \n","\n","       91    92    93    94    95    96    97    98    99  \n","0   -4.95 -0.29  7.86 -0.19 -2.14  3.06  0.34 -4.32  1.07  \n","1    0.00  0.00  9.08  0.00  0.00  0.00  0.00  0.00  0.00  \n","2    0.00  0.00  0.53  0.00  0.00  0.00  0.00  0.00  0.00  \n","3    5.58  4.27  5.19  5.73  1.55  3.11  6.55  1.80  1.60  \n","4   -6.89 -0.68 -2.96 -2.18 -3.35  0.05 -9.08 -5.05 -3.45  \n","..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n","195  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n","196 -2.52 -0.53 -1.89  1.17 -2.04 -1.17 -0.73  0.73  0.44  \n","197  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n","198  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n","199  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n","\n","[200 rows x 100 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["ratings"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NgHE5pV_-xLX"},"source":["Normalize the ratings using StandardScaler and save them in ratings_diff variable"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{},"colab_type":"code","id":"RcvEHdPX-xLY"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","ratings_diff = StandardScaler().fit_transform(ratings)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","id":"PhL5h35h-xLd","outputId":"dad96253-ea96-4d3b-e3ae-acb41ea81723"},"outputs":[{"data":{"text/plain":["array([[ 0.78762067, -0.17252351,  1.37903679, ...,  0.07059963,\n","        -1.36765027,  0.16746078],\n","       [-0.12768256, -0.11295828, -0.06492136, ..., -0.02685824,\n","        -0.04144395, -0.16095388],\n","       [-0.12768256,  1.60210964, -0.06492136, ..., -0.02685824,\n","        -0.04144395, -0.16095388],\n","       ...,\n","       [-0.12768256, -0.11295828, -0.06492136, ..., -0.02685824,\n","        -0.04144395, -0.16095388],\n","       [ 1.1241292 , -1.60825102, -1.1002121 , ..., -0.02685824,\n","        -0.04144395, -0.16095388],\n","       [-0.12768256, -0.11295828, -0.06492136, ..., -0.02685824,\n","        -0.04144395, -0.16095388]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["ratings_diff"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SlgXu_-A-xLh"},"source":["# Popularity based recommendation system"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9XHAA26B-xLi"},"source":["Find the mean for each column in ratings_diff i.e, for each joke"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{},"colab_type":"code","id":"8XXsfbw9-xLi"},"outputs":[],"source":["mean_ratings = ratings_diff.mean(axis=0)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sZCu9JQf-xLo"},"source":["# Consider all the mean ratings and find the jokes with highest mean value and display the top 10 joke IDs."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{},"colab_type":"code","id":"VRasdEen-xLp"},"outputs":[],"source":["mean_ratings = pd.DataFrame(mean_ratings)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{},"colab_type":"code","id":"nr4qpQNF-xL0","outputId":"b12efa05-431e-4bbd-db7e-d0bb3d486d8a"},"outputs":[{"data":{"text/plain":["99    49\n","98    48\n","97    23\n","96    41\n","95    80\n","94    38\n","93    88\n","92    15\n","91    73\n","Name: 0, dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["mean_ratings.iloc[:,0].argsort()[:-10:-1]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N5fTlaRh-xL4"},"source":["# Content based Recommendation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xLMT2wEM-xL4"},"source":["# Context:\n","\n","This dataset contains ratings for ten thousand popular books. As to the source, let's say that these ratings were found on the \n","internet. Generally, there are 100 reviews for each book, although some have less - fewer - ratings. Ratings go from one to five\n","\n","Both book IDs and user IDs are contiguous. For books, they are 1-10000, for users, 1-53424. All users have made at least two \n","ratings. Median number of ratings per user is 8.\n","\n","There are also books marked to read by the users, book metadata (author, year, etc.) and tags.\n","\n","Here is to recommend good book"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ECwR5CbD-xL5"},"source":["# Content:\n","\n","books.csv has metadata for each book (goodreads IDs, authors, title, average rating, etc.).\n","\n","Book metadata.\n","\n","best_book_id is the most popular edition for a given work. Generally it's the same as goodreads_book_id, differs occasionally.\n","\n","books_count is the number of editions for a given work."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XLmDAK6p-xL6"},"source":["# Dataset:\n","    \n","https://www.kaggle.com/zygmunt/goodbooks-10k#books.csv"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{},"colab_type":"code","id":"K1wt8gqs-xL7"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv('./dataset/books.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"4EYEpzFT-xL-","outputId":"faa22658-2308-4b6e-c1c6-07c3146f098e"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4jVXSgut-xMC"},"source":["# Data pre-processing"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{},"colab_type":"code","id":"tI8_FLA8-xMC"},"outputs":[],"source":["# get unique books with title\n","books_sub = df[[\"book_id\",\"title\"]].copy()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{},"colab_type":"code","id":"vendcTl1-xMG","outputId":"c711fca8-58de-4142-ce09-33d3f3eecb78"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>book_id</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2767052</td>\n","      <td>The Hunger Games (The Hunger Games, #1)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41865</td>\n","      <td>Twilight (Twilight, #1)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2657</td>\n","      <td>To Kill a Mockingbird</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4671</td>\n","      <td>The Great Gatsby</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   book_id                                              title\n","0  2767052            The Hunger Games (The Hunger Games, #1)\n","1        3  Harry Potter and the Sorcerer's Stone (Harry P...\n","2    41865                            Twilight (Twilight, #1)\n","3     2657                              To Kill a Mockingbird\n","4     4671                                   The Great Gatsby"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["books_sub.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TAc28cOv-xMJ"},"source":["Vectorize Title"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{},"colab_type":"code","id":"F1f6tqUM-xMK"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{},"colab_type":"code","id":"q8MwTkg2-xMN"},"outputs":[],"source":["# initialize vectorizer\n","#vect = CountVectorizer(analyzer='word',ngram_range=(1,2),stop_words='english', min_df = 0.001)\n","vect = CountVectorizer(analyzer='word',ngram_range=(1,2),stop_words='english', min_df = 0.002) #min_df - rare words , max_df - most used words\n","#ngram_range = (1,2) - if used more than 1(value), lot of features or noise"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{},"colab_type":"code","id":"VGtPwAp_-xMP"},"outputs":[],"source":["vect.fit(books_sub['title'])\n","title_matrix = vect.transform(books_sub['title'])"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{},"colab_type":"code","id":"J1kRFtBH-xMS","outputId":"9f4458ca-72ff-466c-fa7b-f060648310df"},"outputs":[{"data":{"text/plain":["(10000, 261)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["title_matrix.shape"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{},"colab_type":"code","id":"qh71EQwy-xMU","outputId":"27adb952-3f1d-4a03-d658-3fc257da0a4f"},"outputs":[{"ename":"AttributeError","evalue":"'CountVectorizer' object has no attribute 'get_feature_names'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find vocabulary\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mvect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m()\n\u001b[1;32m      3\u001b[0m features\n","\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"]}],"source":["# Find vocabulary\n","features = vect.get_feature_names()\n","features"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{},"colab_type":"code","id":"rFJFOwJ8-xMX","outputId":"f47d25fb-7943-49dc-ddf7-ec665d1974b2"},"outputs":[{"ename":"NameError","evalue":"name 'features' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mfeatures\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"]}],"source":["len(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Ff7XKNWI-xMa"},"outputs":[],"source":["What happens when we change the value of min_df value? What is this argument controlling?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"wpHztaaH-xMc","outputId":"794a3c11-e8c6-4893-bdcf-fbfd852f9659"},"outputs":[],"source":["# confirm count of features in the corpus\n","word_count = [books_sub[\"title\"].str.contains(\"\\\\b\"+x+\"\\\\b\", case=False).sum() for x in features]\n","word_count"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U0Us3HRp-xMf"},"source":["# Find Similarity Between Items"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"OA_n4Ftu-xMg"},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"CHJW6Mn1-xMi"},"outputs":[],"source":["cosine_sim_titles = cosine_similarity(title_matrix, title_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"mpnJlpFy-xMl","outputId":"1f1b4369-03bb-4546-97b0-d50e5f5ff7af"},"outputs":[],"source":["cosine_sim_titles.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"LdgpejIv-xMo","outputId":"ed1379e8-c8ec-4810-e62a-b92473f5f570"},"outputs":[],"source":["# get books similiar to a given title\n","title_id = 3\n","books_sub['title'].iloc[title_id]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"mKxCd7Yj-xMr","outputId":"c7507afd-b832-43a4-bcf7-74147581b46f"},"outputs":[],"source":["np.argsort(cosine_sim_titles[1,])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"DC6s9EGh-xMv","outputId":"b1c1cf46-03f0-46c0-c673-582a4b55fd82"},"outputs":[],"source":["top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]),axis=0)[0:10]\n","top_n_sim_values = cosine_sim_titles[title_id, top_n_idx]\n","top_n_sim_values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"dpkKLhAp-xMx"},"outputs":[],"source":["# find top n with values > 0\n","top_n_idx = top_n_idx[top_n_sim_values > 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"lZ9SKYxv-xM0","outputId":"f12d7220-2398-4baa-d0ea-9b4507607699"},"outputs":[],"source":["# Matching books\n","books_sub['title'].iloc[top_n_idx]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bVrpyIUF-xM2"},"source":["# Consider the book - \"To Kill a Mockingbird\" (location_id - 3). \n","What are the most similiar books? Why does \"First to Kill\", \"Kill me if you can\" etc all have same ratings?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Ky61hGGf-xM3","outputId":"96e72c77-af37-4055-ed27-db22be2f1292"},"outputs":[],"source":["## get books similiar to a given title\n","title_id = 1 # make this 3\n","books_sub['title'].iloc[title_id]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0g0tI_Cp-xM6"},"source":["# Find out what features have been considered by the vectorizer for a given title?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ntzcbZPI-xM7","outputId":"73f79351-bb9e-461d-f785-2721a2961cfa"},"outputs":[],"source":["np.where(np.squeeze(title_matrix[9247,].toarray()) > 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"vRGjOABB-xM9","outputId":"4b24e184-d487-436b-8552-3d0af8c253b3"},"outputs":[],"source":["features[245]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"rvuhgsME-xNA","outputId":"528397a2-9ad5-4d62-9258-090a375c6af2"},"outputs":[],"source":["# To find out non-zero values from the Count vectorizer matrix\n","title_id = 7017\n","feature_array = np.squeeze(title_matrix[title_id,].toarray())\n","idx = np.where(feature_array > 0)\n","idx[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Il8495hQ-xND","outputId":"86149a20-10b9-4f9a-e843-627f682f5370"},"outputs":[],"source":["[features[x] for x in idx[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"jWsjpL0E-xNG"},"outputs":[],"source":["# lets wrap the above code in a function\n","def return_sim_books(title_id, title_matrix, vectorizer, top_n = 10):\n","    \n","    # generate sim matrix\n","    sim_matrix = cosine_similarity(title_matrix, title_matrix)\n","    features = vectorizer.get_feature_names()\n","\n","\n","\n","    top_n_idx = np.flip(np.argsort(sim_matrix[title_id,]),axis=0)[0:top_n]\n","    top_n_sim_values = sim_matrix[title_id, top_n_idx]\n","    \n","    # find top n with values > 0\n","    top_n_idx = top_n_idx[top_n_sim_values > 0]\n","    scores = top_n_sim_values[top_n_sim_values > 0]\n","    \n","    \n","    # find features from the vectorized matrix\n","    sim_books_idx = books_sub['title'].iloc[top_n_idx].index\n","    words = []\n","    for book_idx in sim_books_idx:\n","        try:\n","            feature_array = np.squeeze(title_matrix[book_idx,].toarray())\n","        except:\n","            feature_array = np.squeeze(title_matrix[book_idx,])\n","        idx = np.where(feature_array > 0)\n","        words.append([\" , \".join([features[i] for i in idx[0]])])\n","        \n","    # collate results\n","    res = pd.DataFrame({\"book_title\" : books_sub['title'].iloc[title_id],\n","           \"sim_books\": books_sub['title'].iloc[top_n_idx].values,\"words\":words,\n","           \"scores\":scores}, columns = [\"book_title\",\"sim_books\",\"scores\",\"words\"])\n","    \n","    \n","    return res\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"p-OvLJje-xNK","outputId":"e3b80b51-8447-49f8-e0f5-8b5a49524c28"},"outputs":[],"source":["vect = CountVectorizer(analyzer='word',ngram_range=(1,2),stop_words='english', min_df = 0.001)\n","vect.fit(books_sub['title'])\n","title_matrix = vect.transform(books_sub['title'])\n","return_sim_books(1854,title_matrix,vect,top_n=20)"]}],"metadata":{"colab":{"name":"W1_CS_PB_CB_Jester_Books.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
